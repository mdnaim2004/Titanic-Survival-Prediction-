<div align="center">

```text
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•       â•šâ•â•   â•šâ•â•   â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â• â•šâ•â•â•â•â•â•


## ğŸš¢ RMS TITANIC â€” MACHINE LEARNING PROJECT

# ğŸš¢ Titanic Survival Prediction using Machine Learning

A complete **end-to-end Machine Learning classification project** that predicts whether a passenger survived the Titanic disaster using demographic, social, and travel-related features.

This project demonstrates the full Data Science workflow â€” from **data preprocessing â†’ exploratory analysis â†’ feature engineering â†’ model training â†’ evaluation â†’ prediction**.

---

## ğŸ“Œ Project Overview

The objective of this project is to build a robust classification model that can accurately predict:

> **Survival Status**  
> `0 = Did Not Survive`  
> `1 = Survived`

The notebook covers the complete ML lifecycle:

- ğŸ“¥ Data loading and initial exploration  
- ğŸ§¹ Data cleaning and preprocessing  
- ğŸ” Exploratory Data Analysis (EDA)  
- ğŸ§  Feature engineering  
- ğŸ¤– Model training with multiple algorithms  
- ğŸ“Š Model evaluation and comparison  
- ğŸ¯ Final prediction pipeline  

This project is designed for **learning, experimentation, and Kaggle-style workflow practice**.

---

## ğŸ“‚ Dataset Information

The dataset contains detailed passenger information from the Titanic.

### ğŸ”‘ Features Description

| Feature | Description |
|--------|------------|
| PassengerId | Unique passenger identifier |
| Pclass | Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd) |
| Name | Passenger full name |
| Sex | Gender of the passenger |
| Age | Age in years |
| SibSp | Number of siblings/spouses aboard |
| Parch | Number of parents/children aboard |
| Ticket | Ticket number |
| Fare | Ticket fare paid |
| Cabin | Cabin number (many missing values) |
| Embarked | Port of embarkation (C, Q, S) |
| Survived | Target variable (0/1) |

---

## âš™ï¸ Machine Learning Workflow

### 1ï¸âƒ£ Data Preprocessing

Key preprocessing steps:

- Handling missing values (Age, Cabin, Embarked)  
- Encoding categorical variables (Sex, Embarked)  
- Dropping irrelevant or high-missing columns  
- Converting data into model-friendly format  
- Trainâ€“test split  

---

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)

EDA helps uncover hidden patterns and relationships.

ğŸ“Š Analyses performed:

- Survival rate by **gender**  
- Survival rate by **passenger class**  
- Age distribution of survivors vs non-survivors  
- Fare distribution analysis  
- Correlation heatmap for numeric features  

ğŸ’¡ Key insights:

- Female passengers had a significantly higher survival rate  
- 1st class passengers survived more than 3rd class  
- Younger passengers had slightly better survival probability  

---

### 3ï¸âƒ£ Feature Engineering

New meaningful features were created to improve model performance:

- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ **FamilySize** = SibSp + Parch + 1  
- ğŸ§ **IsAlone** (binary feature)  
- ğŸ·ï¸ **Title extraction** from passenger names (Mr, Mrs, Miss, etc.)  
- Age group binning (optional)  

Feature engineering helps the model learn **social patterns** rather than raw data.

---

### 4ï¸âƒ£ Model Building

Multiple classification algorithms were trained and compared:

- Logistic Regression  
- Decision Tree Classifier  
- Random Forest Classifier  
- K-Nearest Neighbors (KNN)  

Each model was trained on the same processed dataset to ensure fair comparison.

---

### 5ï¸âƒ£ Model Evaluation

Models were evaluated using:

- âœ… Accuracy Score  
- ğŸ“‰ Confusion Matrix  
- ğŸ“‹ Classification Report  
  - Precision  
  - Recall  
  - F1-Score  

This helps identify:

- Overfitting vs underfitting  
- Class imbalance behavior  
- Best performing model  

---

## ğŸ§  Machine Learning Pipeline

```text
Raw Data
   â†“
Data Cleaning & Missing Value Handling
   â†“
Exploratory Data Analysis (EDA)
   â†“
Feature Engineering
   â†“
Encoding & Feature Selection
   â†“
Trainâ€“Test Split
   â†“
Model Training (Multiple Algorithms)
   â†“
Model Evaluation & Comparison
   â†“
Final Prediction
